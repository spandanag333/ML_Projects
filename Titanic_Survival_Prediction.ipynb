{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic Survival Prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c29PiG2BuxOM"
      },
      "source": [
        "# Importing important libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kXoMJvyryIk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xb-OmXuu7A2"
      },
      "source": [
        "# Reading the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdZVRZt-u39A"
      },
      "source": [
        "url = \"https://raw.github.com/mattdelhey/kaggle-titanic/master/Data/train.csv\"\n",
        "titanic = pd.read_csv(url) \n",
        "titanic.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c92Yo-gmvGbi"
      },
      "source": [
        "# Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXIpMuU1vAWd"
      },
      "source": [
        "titanic.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWFQW4UUvLGU"
      },
      "source": [
        "There are **891** rows & **11 columns**. This means there are 891 datapoints in the dataset & 11 features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmqvkkcWvKJT"
      },
      "source": [
        "titanic.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB1c8nwpvrGc"
      },
      "source": [
        "Out of these features, the feature **'survived' is the target feature**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5CaCdvlvoAi"
      },
      "source": [
        "titanic.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7Ys_pTKwA7A"
      },
      "source": [
        "*  There are **5 object fields** which needs to be encoded. \n",
        "\n",
        "*  'age', 'cabin' & embarked has some **missing values**\n",
        "\n",
        "\n",
        "So I need to know how many Nan values are there in each columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jFzc5dAwl-o"
      },
      "source": [
        "titanic.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmthd8eIxBx6"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOSgi-m-w3pC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(titanic.corr(), annot=True, linewidths=0.5, fmt= '.3f')       #Plot rectangular data as a color-encoded matrix."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xezPNknAxP7c"
      },
      "source": [
        "titanic.corr()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkyG53d1yM0w"
      },
      "source": [
        "By the previous knowledge we have, let's create a new feature telling **whether the passenger is man, woman or a child.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRwejFqrxSs4"
      },
      "source": [
        "def woman_child_or_man(passenger):\n",
        "    age, sex = passenger\n",
        "    if age < 16:\n",
        "        return \"child\"\n",
        "    else:\n",
        "        return dict(male=\"man\", female=\"woman\")[sex]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHeMKAqqxtR_"
      },
      "source": [
        "titanic[\"who\"] = titanic[[\"age\", \"sex\"]].apply(woman_child_or_man, axis=1) #we dont have any column who earlier so it will be created\n",
        "#.apply is a keyword that applies the function woman_child_or_man to the specified columns # axis=1 means one row at a time( the possible values are o and 1)\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4ZYpEvf0RXl"
      },
      "source": [
        "We will create another feature to see wether a person was an adult male or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC2seGyaxyoh"
      },
      "source": [
        "titanic[\"adult_male\"] = titanic.who == \"man\"\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPORNJXp0MBd"
      },
      "source": [
        "We can have another feature with the deck information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjIUqg6jx9oT"
      },
      "source": [
        "titanic[\"deck\"] = titanic.cabin.str[0]\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P98XMiVPz4ft"
      },
      "source": [
        "Now one more feature can be created, whether the passenger was alone or not. So let's do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppOf9NMz0AvF"
      },
      "source": [
        "titanic[\"alone\"] = ~(titanic.parch + titanic.sibsp).astype(bool)\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQJaUBF31g_Q"
      },
      "source": [
        "Now let's try to look at the trends in different feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m155JX5K0Bpt"
      },
      "source": [
        "sns.factorplot(\"pclass\", \"survived\", data=titanic).set(ylim=(0, 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apn3iKAK1mYm"
      },
      "source": [
        "From here we see that if a passenger travelled in 1st class, the survival rate is highest and equal to 0.63. If a passenger travelled in 2nd class, the survival rate is medium and equal to 0.5. If a passenger travelled in 3rd class, the survival rate is lowest and equal to 0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMIbVdvy2EDC"
      },
      "source": [
        "Let's see how the above case is dependent on the **sex of the passenger.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdsDQ5WP0Goe"
      },
      "source": [
        "sns.factorplot(\"pclass\", \"survived\", data=titanic, hue=\"sex\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSl5Gqnj2U6z"
      },
      "source": [
        "It;s pretty clear that the surviavl of female passengers is much more than the male passengers. From here we see that if a passenger travelled in 1st class and was female then their survival chance is most. On the other hand, if a passenger travelled in 3rd class amd was male then their survival chance is least. So we can combine these two features to **create new feature**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMdQjxmU5L3U"
      },
      "source": [
        "Let's have a similar observation with the features **'class' & 'who'**  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWpCtlDr2Qvb"
      },
      "source": [
        "sns.factorplot(\"pclass\", \"survived\", data=titanic, hue=\"who\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNdb0jKk5wHZ"
      },
      "source": [
        "From here also we can have similar observation. We get 9 cases from here and we will be building a feature based on it in a while."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOWG9wDf6c0Y"
      },
      "source": [
        "Let's try to find the trends with **the feature 'alone' & 'adult_male'**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGXCl_9D-cff"
      },
      "source": [
        "sns.factorplot(\"alone\", \"survived\", data=titanic, hue=\"sex\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfEDPeOR-scj"
      },
      "source": [
        "sns.factorplot(\"adult_male\", \"survived\", data=titanic, hue=\"sex\").set(ylim=(0, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_deIKVcp57jP"
      },
      "source": [
        "Now let's see what effect does the feature **'deck'** has."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk-iz28v5myt"
      },
      "source": [
        "sns.barplot(\"deck\", \"survived\", data=titanic,order=['A','B','C','D','E','F','G'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_xp1GQ06TLb"
      },
      "source": [
        "Now let's try to combine 3 features together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vXNivF76Cin"
      },
      "source": [
        "sns.factorplot(\"alone\", \"survived\", data=titanic, hue=\"sex\",col=\"pclass\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpLM5JwG-4dG"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFZDO8Jt_Iu1"
      },
      "source": [
        "Let's have the object fields encoded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlHRO8s06OmW"
      },
      "source": [
        "#encoding deck\n",
        "#encoding means to replace a particular object with another\n",
        "dk = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7} #we are replacing A with 1,B with 2 and so on....        \n",
        "titanic['deck']=titanic.deck.map(dk) #we are replacing the values in the column deck with the ones like declared in dk.\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Mfx_3oa_ppH"
      },
      "source": [
        "# encoding embarked\n",
        "\n",
        "\n",
        "titanic['embarked'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOADubwe_ZIA"
      },
      "source": [
        "e = {'S':3,'Q':2, 'C':1}\n",
        "titanic['embarked']=titanic.embarked.map(e)\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUj1AlQzAGTM"
      },
      "source": [
        "# encoding gender\n",
        "\n",
        "genders = {\"male\": 0, \"female\": 1}\n",
        "titanic['sex'] = titanic.sex.map(genders)  #titanic['sex'].map(genders)\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSizNzLAAPS6"
      },
      "source": [
        "#encoding who\n",
        "\n",
        "wh = {'child':3,'woman':2, 'man':1}\n",
        "titanic['who']=titanic.who.map(wh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5PENJzKAU4Q"
      },
      "source": [
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdBESBiJA1fB"
      },
      "source": [
        "Now we need to impute the **Missing Values**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr4guzZ2BfrF"
      },
      "source": [
        "There are alot of missing values in deck. So we will simply fill it with **0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MMFgt7qAciv"
      },
      "source": [
        "#imputing deck\n",
        "titanic['deck']=titanic['deck'].fillna(0)     #to replace the Nan values by 0\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EqJIuNZBybS"
      },
      "source": [
        "There are only 2 missing vaues in 'embarked'. So we will find out which of the values in embarked has **maximum occurence** and fill the missing values with **that value**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eem95ZtcBHO3"
      },
      "source": [
        "#imputing embarked\n",
        "\n",
        "titanic['embarked'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i12cqpmBPN-"
      },
      "source": [
        "titanic['embarked']=titanic['embarked'].fillna('3.0')\n",
        "titanic.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y21lkD1ZCQ7E"
      },
      "source": [
        "Now we will impute the missing values in **'age'**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KkSk3J-BUWl"
      },
      "source": [
        "#imputing age\n",
        "\n",
        "m=titanic['age'].mean()\n",
        "m\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIbn8JYsGqjR"
      },
      "source": [
        "titanic['age']=titanic['age'].fillna(m)\n",
        "titanic.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIDuSpxPHAwT"
      },
      "source": [
        "# Adding New Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3dXBIXbG18O"
      },
      "source": [
        "def process_family(parameters):\n",
        "     \n",
        "    x,y=parameters\n",
        "    \n",
        "    # introducing a new feature : the size of families (including the passenger)\n",
        "    family_size = x+ y + 1\n",
        "    \n",
        "    if (family_size==1):\n",
        "      return 1 # for singleton\n",
        "    elif(2<= family_size <= 4 ):\n",
        "      return 2 #for small family\n",
        "    else:\n",
        "      return 3 #for big family "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBEBYrWNHMxL"
      },
      "source": [
        "titanic['FAM_SIZE']= titanic[['parch','sibsp']].apply(process_family, axis=1)\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp_7HPNcHOv_"
      },
      "source": [
        "# to get title from the name.\n",
        "\n",
        "titles = set()\n",
        "for name in titanic['name']:\n",
        "    titles.add(name.split(',')[1].split('.')[0].strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiIr98SYHWua"
      },
      "source": [
        "titles #all the salutations present in my dataset."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj9bsp2LHYjm"
      },
      "source": [
        "len(titles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sqIBnclHbVK"
      },
      "source": [
        "Title_Dictionary = {\n",
        "    \"Capt\": \"Officer\",\n",
        "    \"Col\": \"Officer\",\n",
        "    \"Major\": \"Officer\",\n",
        "    \"Jonkheer\": \"Royalty\",\n",
        "    \"Don\": \"Royalty\",\n",
        "    \"Sir\" : \"Royalty\",\n",
        "    \"Dr\": \"Officer\",\n",
        "    \"Rev\": \"Officer\",\n",
        "    \"the Countess\":\"Royalty\",\n",
        "    \"Mme\": \"Mrs\",\n",
        "    \"Mlle\": \"Miss\",\n",
        "    \"Ms\": \"Mrs\",\n",
        "    \"Mr\" : \"Mr\",\n",
        "    \"Mrs\" : \"Mrs\",\n",
        "    \"Miss\" : \"Miss\",\n",
        "    \"Master\" : \"Master\",\n",
        "    \"Lady\" : \"Royalty\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryWoGhk3Hete"
      },
      "source": [
        "def get_titles():\n",
        "    # we extract the title from each name\n",
        "    titanic['title'] = titanic['name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
        "    \n",
        "    # a map of more aggregated title\n",
        "    # we map each title\n",
        "    titanic['title'] = titanic.title.map(Title_Dictionary)\n",
        "    return titanic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOA5PuwdHmvu"
      },
      "source": [
        "titanic = get_titles()\n",
        "titanic.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aeVgTMbH3Bp"
      },
      "source": [
        "Now we need to encode these titles. Right now I will use one-hot encoding with this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI1271H-HqGY"
      },
      "source": [
        "titles_dummies = pd.get_dummies(titanic['title'], prefix='title')\n",
        "titanic = pd.concat([titanic, titles_dummies], axis=1)\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGX79S9BIUiB"
      },
      "source": [
        "And finally the Feature that we observed during the visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TZUIJ35IDDK"
      },
      "source": [
        "def new_fe(parameters):\n",
        "  p,w=parameters\n",
        "  \n",
        "  if (p==1):\n",
        "    if (w==1):\n",
        "      return 1\n",
        "    elif (w==2):\n",
        "      return 2\n",
        "    elif (w==3):\n",
        "      return 3\n",
        "  elif (p==2):\n",
        "    if (w==1):\n",
        "      return 4\n",
        "    elif (w==2):\n",
        "      return 5\n",
        "    elif (w==3):\n",
        "      return 6\n",
        "  elif (p==3):\n",
        "    if (w==1):\n",
        "      return 7\n",
        "    elif (w==2):\n",
        "      return 8\n",
        "    elif (w==3):\n",
        "      return 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zm6wGgBJaFh"
      },
      "source": [
        "titanic['pcl_wh']= titanic[['pclass','who']].apply(new_fe, axis=1)\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCpP4FZgKfki"
      },
      "source": [
        "Now we will drop all the features which I don't want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEVJGSKwKUxS"
      },
      "source": [
        "titanic.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_tvIyhYKlWO"
      },
      "source": [
        "drop_list=['name','ticket','fare', 'cabin','title']\n",
        "titanic = titanic.drop(drop_list, axis=1)\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv3LPjFvLPgl"
      },
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "sns.heatmap(titanic.corr(), annot=True, linewidths=0.5, fmt= '.3f')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo5llYFwufni"
      },
      "source": [
        "# Build the Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOUII3fBu-ZY"
      },
      "source": [
        "The first task will be to **split the dataset** into train set and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7TpuKz-ttDZ"
      },
      "source": [
        "X_train = titanic.drop(\"survived\", axis=1)\n",
        "Y_train = titanic[\"survived\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSzY7JyevBH6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# splitting data in training set(70%) and test set(30%).\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7DJ1GSmwDrB"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9gyCWRPfxfn"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe_AogD4jz8v"
      },
      "source": [
        "titanic.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEUJ9JskvK_p"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        " \n",
        "lr = LogisticRegression() #create the object of the model\n",
        "lr = lr.fit(x_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXy1m0_Sw6I2"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix,precision_score,recall_score,f1_score\n",
        "\n",
        "act = accuracy_score(y_train,lr.predict(x_train))\n",
        "print('Training Accuracy is: ',(act*100))\n",
        "p = precision_score(y_train,lr.predict(x_train))\n",
        "print('Training Precision is: ',(p*100))\n",
        "r = recall_score(y_train,lr.predict(x_train))\n",
        "print('Training Recall is: ',(r*100))\n",
        "f = f1_score(y_train,lr.predict(x_train))\n",
        "print('Training F1 Score is: ',(f*100))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAESUcAkvZoh"
      },
      "source": [
        "act = accuracy_score(y_test,lr.predict(x_test))\n",
        "print('Test Accuracy is: ',(act*100))\n",
        "p = precision_score(y_test,lr.predict(x_test))  # total how many right predictions are given.\n",
        "print('Test Precision is: ',(p*100))         \n",
        "r = recall_score(y_test,lr.predict(x_test))   #how much the prediction is actually right\n",
        "print('Test Recall is: ',(r*100))\n",
        "f = f1_score(y_test,lr.predict(x_test))         #(2*p*r)/(p+r)\n",
        "print('Test F1 Score is: ',(f*100))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBtSEfJk3At8"
      },
      "source": [
        "## Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeKalFUn3MPR"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(criterion = \"gini\", \n",
        "                                       min_samples_leaf = 3, \n",
        "                                       min_samples_split = 10,   \n",
        "                                       n_estimators=100, \n",
        "                                       max_features=0.5, \n",
        "                                       oob_score=True, \n",
        "                                       random_state=1, \n",
        "                                       n_jobs=-1)\n",
        "rf = rf.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UwcWQx03Yn3"
      },
      "source": [
        "act = accuracy_score(y_train,rf.predict(x_train))\n",
        "print('Training Accuracy is: ',(act*100))\n",
        "p = precision_score(y_train,rf.predict(x_train))\n",
        "print('Training Precision is: ',(p*100))\n",
        "r = recall_score(y_train,rf.predict(x_train))\n",
        "print('Training Recall is: ',(r*100))\n",
        "f = f1_score(y_train,rf.predict(x_train))\n",
        "print('Training F1 Score is: ',(f*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnmZsPiU3Yac"
      },
      "source": [
        "act = accuracy_score(y_test,rf.predict(x_test))\n",
        "print('Test Accuracy is: ',(act*100))\n",
        "p = precision_score(y_test,rf.predict(x_test))\n",
        "print('Test Precision is: ',(p*100))\n",
        "r = recall_score(y_test,rf.predict(x_test))\n",
        "print('Test Recall is: ',(r*100))\n",
        "f = f1_score(y_test,rf.predict(x_test))\n",
        "print('Test F1 Score is: ',(f*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0pnebpNyKZG"
      },
      "source": [
        "## Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7r8ZExHvolc"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt=dt.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxObawiNyd-U"
      },
      "source": [
        "act = accuracy_score(y_train,dt.predict(x_train))\n",
        "print('Training Accuracy is: ',(act*100))\n",
        "p = precision_score(y_train,dt.predict(x_train))\n",
        "print('Training Precision is: ',(p*100))\n",
        "r = recall_score(y_train,dt.predict(x_train))\n",
        "print('Training Recall is: ',(r*100))\n",
        "f = f1_score(y_train,dt.predict(x_train))\n",
        "print('Training F1 Score is: ',(f*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBFZ9HYj2vNY"
      },
      "source": [
        "act = accuracy_score(y_test,dt.predict(x_test))\n",
        "print('Test Accuracy is: ',(act*100))\n",
        "p = precision_score(y_test,dt.predict(x_test))\n",
        "print('Test Precision is: ',(p*100))\n",
        "r = recall_score(y_test,dt.predict(x_test))\n",
        "print('Test Recall is: ',(r*100))\n",
        "f = f1_score(y_test,dt.predict(x_test))\n",
        "print('Test F1 Score is: ',(f*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dbPItbGXRoD"
      },
      "source": [
        "# **K-Nearest Neighbour(KNN)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMjSv1j1XnWw"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "knn = KNeighborsClassifier(n_neighbors = 1) \n",
        "knn.fit(x_train, y_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4BPUqr3Y5yg"
      },
      "source": [
        "act = accuracy_score(y_train,knn.predict(x_train))\n",
        "print('Training Accuracy is: ',(act*100))\n",
        "p = precision_score(y_train,knn.predict(x_train))\n",
        "print('Training Precision is: ',(p*100))\n",
        "r = recall_score(y_train,knn.predict(x_train))\n",
        "print('Training Recall is: ',(r*100))\n",
        "f = f1_score(y_train,knn.predict(x_train))\n",
        "print('Training F1 Score is: ',(f*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWSiB7CrZTD3"
      },
      "source": [
        "act = accuracy_score(y_test,knn.predict(x_test))\n",
        "print('Test Accuracy is: ',(act*100))\n",
        "p = precision_score(y_test,knn.predict(x_test))\n",
        "print('Test Precision is: ',(p*100))\n",
        "r = recall_score(y_test,knn.predict(x_test))\n",
        "print('Test Recall is: ',(r*100))\n",
        "f = f1_score(y_test,knn.predict(x_test))\n",
        "print('Test F1 Score is: ',(f*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF0eI56AZc-O"
      },
      "source": [
        "**Support Vector Machine(SVM)**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3C2eCvIaM-b"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svc = SVC(kernel='linear')\n",
        "svc.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1-LNbR5aTn3"
      },
      "source": [
        "act = accuracy_score(y_train,svc.predict(x_train))\n",
        "print('Training Accuracy is: ',(act*100))\n",
        "p = precision_score(y_train,svc.predict(x_train))\n",
        "print('Training Precision is: ',(p*100))\n",
        "r = recall_score(y_train,svc.predict(x_train))\n",
        "print('Training Recall is: ',(r*100))\n",
        "f = f1_score(y_train,svc.predict(x_train))\n",
        "print('Training F1 Score is: ',(f*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wX4xdW3a_a6"
      },
      "source": [
        "act = accuracy_score(y_test,svc.predict(x_test))\n",
        "print('Test Accuracy is: ',(act*100))\n",
        "p = precision_score(y_test,svc.predict(x_test))\n",
        "print('Test Precision is: ',(p*100))\n",
        "r = recall_score(y_test,svc.predict(x_test))\n",
        "print('Test Recall is: ',(r*100))\n",
        "f = f1_score(y_test,svc.predict(x_test))\n",
        "print('Test F1 Score is: ',(f*100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}